---
title: "assay developement"
subtitle: "__machine learning base learner__"
author: "_umahajan_"
date:  "`r format(Sys.time(), '%d %B, %Y')`"
output:
  html_notebook:
    theme: united
    number_sections: yes
    toc: yes
    toc_depth: 4
    toc_float: true
---

```{r setup, include=FALSE}
chooseCRANmirror(graphics = TRUE, ind = 1)
knitr::opts_chunk$set(
  tidy.opts = list(width.cutoff = 85),
  tidy = TRUE,
  echo = TRUE,
  warning = FALSE,
  message = FALSE
)
```

# load packages and datasets
```{r packages}
rm(list = ls())
##---------------------------------------------------------------
##                      required packages                      --
##---------------------------------------------------------------
scriptLibraries <-  c(
  "here",
  "dplyr",
  "openxlsx",
  "janitor",
  "rmarkdown",
  "knitr",
  "kableExtra",
  "tidyr",
  "ggplot2",
  "ggridges",
  "arsenal",
  "RColorBrewer",
  "h2o",
  "caret",
  "lime",
  "ggpubr",
  "sjPlot",
  "fmsb",
  "auctestr",
  "purrr",
  "tibble"
)
##---------------------------------------------------------------
##                      load functions                         --
##---------------------------------------------------------------
source("~/r_functions/basicFunctions.R")
source("~/r_functions/runH2Omodels.R") ## require to load h2o 
##---------------------------------------------------------------
##                        load packages                        --
##---------------------------------------------------------------
installScriptLibs(scriptLibraries)
##----------------------------------------------------------------
##                         basic themes                         --
##----------------------------------------------------------------
ggplot_theme <- theme_bw() +
  theme(
    axis.line = element_line(size = 0.75),
    axis.text = element_text(
      size = 11,
      face = "bold",
      colour = "black"
    ),
    axis.title = element_text(size = 12, face = "bold")
  )
##---------------------------------------------------------------
##                    set working directory                    --
##---------------------------------------------------------------
here::here()
```

## initiate h2o
```{r h2o}
##----------------------------------------------------------------
##             detect the number of cores available             --
##----------------------------------------------------------------
myCores = parallel::detectCores(all.tests = TRUE) - 1

if (myCores > 20) {
  myCores = 20
} else
  myCores = myCores


memFreeG = 50
# Sys.setenv(JAVA_HOME = "/dss/dsshome1/lxc00/ru64waf2/bin/jdk-13.0.2")
##----------------------------------------------------------------
##                         initiate h2o                         --
##----------------------------------------------------------------
h2o.init(
  nthreads = myCores,
  min_mem_size = paste(memFreeG, "g", sep = ""),
  max_mem_size = paste(memFreeG, "g", sep = "")
)
h2o.no_progress()
h2o.removeAll()
```

# keys

```{r keys}
##---------------------------------------------------------------
##                         define keys                         --
##---------------------------------------------------------------
time <- 60*60
prevalence = 1.95/100
```

# load data
```{r dat}
##---------------------------------------------------------------
##                          load data                          --
##---------------------------------------------------------------
train <- readRDS("./ml_dataset/ImputedTrain.rds")
testComplete <- readRDS("./ml_dataset/ImputedTest.rds")
test <- testComplete[!testComplete$Diagnosis %in% "Non-pancreatic control",]
validationComplete <- readRDS("./ml_dataset/ImputedValidation.rds")
validation <- validationComplete[!validationComplete$Diagnosis %in% "Non-pancreatic control",]
# load metabolite names ---------------------------------------------------
metaboliteNames <- 
 read.csv("./masterTable/masterTableMetaboliteNames.csv",
          stringsAsFactors = FALSE)
```

## define response and features
```{r response}
##----------------------------------------------------------------
##                   define response variable                   --
##----------------------------------------------------------------
response <- "Disease_status"
train[[response]] <- as.factor(train[[response]])
test[[response]] <- as.factor(test[[response]])
validation[[response]] <- as.factor(validation[[response]])
##----------------------------------------------------------------
##                        merge features                        --
##----------------------------------------------------------------
columnToselect <- c( "^X", response)
features <-
 setdiff(colnames(train)[grepl(paste(columnToselect, collapse ="|"), colnames(train))], response)

## load selected m-metabolite model
selected.model <- h2o.loadModel(paste0(here(),"/h2o_results/feature_reduction/GLM_1_AutoML_20211203_140114"))

features_selected_model <- selected.model@parameters$x

features <- intersect(features, features_selected_model)
```

# low CA
```{r}
train <- train[train$lowCA %in% "low", ]
test <- test[test$lowCA %in% "low", ]
validation <- validation[validation$lowCA %in% "low", ]
```


# Exploratory data analysis
```{r eda}
##---------------------------------------------------------------
##             create results/prediction directory             --
##---------------------------------------------------------------
ifelse(!dir.exists(file.path(paste0(here()), "h2o_results")),
       dir.create(file.path(paste0(here()), "h2o_results")), 
       FALSE)
## save pdfs
pdf("./h2o_results/eda_lowCA.pdf", 
    paper= "a4",
    onefile = TRUE)
## plot distribution Train
a <- train %>%
  ggplot(aes(x = Disease_status, fill = Disease_status)) +
  geom_bar() +
  guides(fill = FALSE) +
  geom_label(stat = 'count', aes(label = ..count..), size = 7) +
  ggplot_theme +
  ggtitle("training set") +
  xlab("") +
  scale_fill_manual(values = c("#E41A1C", "#377EB8"))
## plot distribution Test
b <- test %>%
  ggplot(aes(x = Disease_status, fill = Disease_status)) +
  geom_bar() +
  guides(fill = FALSE) +
  geom_label(stat = 'count', aes(label = ..count..), size = 7) +
  ggplot_theme +
  ggtitle("testing set") +
  xlab("") +
  scale_fill_manual(values = c("#E41A1C", "#377EB8"))
## plot distribution validatio
c <- validation %>%
  ggplot(aes(x = Disease_status, fill = Disease_status)) +
  geom_bar() +
  guides(fill = FALSE) +
  geom_label(stat = 'count', aes(label = ..count..), size = 7) +
  ggplot_theme +
  ggtitle("validation set") +
  xlab("") +
  scale_fill_manual(values = c("#E41A1C", "#377EB8"))
## merge
p <- ggarrange(a, b, c, ncol = 3, labels = c("A", "B", "C"))
              
print(p)
dev.off()

print(p)
```

# automl modelling

## h2o dataframe
```{r h2o df}
##----------------------------------------------------------------
##                        convert h2o df                        --
##----------------------------------------------------------------
train <- as.h2o(train)
test <- as.h2o(test)
validation <- as.h2o(validation)
```

## h2o results
```{r res}
ifelse(!dir.exists(file.path(paste0(here()), "h2o_results/base_lowCA")),
       dir.create(file.path(paste0(here()), "h2o_results/base_lowCA")), 
       FALSE)
```

## select h2o model

```{r h2o fun}
## base model
banner("base model")
base <- runBaseModel(train = train,
                     test = test,
                     features = features,
                     response = response,
                     time = time,
                     exclude_algos = c("XGBoost", "DeepLearning", "StackedEnsemble","GBM", "DRF"),
                     save.location = paste0(here(),"/h2o_results/base_lowCA/"), cutoff_metric = "f1")
## plot
p <- base$plot
print(p)
save_plot(
  "./svg/h2o_varImp_base_lowCA.svg",
  fig = p,
  width = 15,
  height = 9,
  dpi = 300
)
## lederboard
head(base$leaderboard)
## model performance
base$performance
## summary
tab_df(base$result)
## cross validation score
tab_df(base$cv.results)

## cutoff of selected model
cutoff.selected.model <- h2o.find_threshold_by_max_metric(h2o.performance(base$model, test), "f1") 
cutoff.selected.model
```

## selected model summary

```{r}
p <- plotVarImp(base$model)

## print
print(p)
save_plot(
  "./svg/h2o_varImp_selectedModel_lowCA.svg",
  fig = p,
  width = 15,
  height = 9,
  dpi = 300
)

prevalence = 1.95/100

banner("test performance")
perf.test <- h2o.performance(selected.model, test)
perf.test
## cutoff of selected model
cutoff.selected.model <- h2o.find_threshold_by_max_metric(perf.test, "f1")
## confusion matrix
cm <- as.data.frame(h2o.confusionMatrix(perf.test, cutoff.selected.model))
## enlist categories
lvs <- c("CP", "PDAC")
## truth
truth <- factor(rep(lvs, times = c(cm$CP[1] + cm$PDAC[1], cm$CP[2] + cm$PDAC[2])), levels = rev(lvs))
## pred 
pred <- factor(c(rep(lvs, times = c(cm$CP[1], cm$PDAC[1])), rep(lvs, times = c(cm$CP[2], 
    cm$PDAC[2]))), levels = rev(lvs))
## xtab
xtab <- table(pred, truth)
## confusion matrix
cm <- confusionMatrix(xtab, positive = "PDAC", prevalence = prevalence)
cm
plotCM(cm)


banner("validation performance")
perf.validation <- h2o.performance(selected.model, validation)
perf.validation
## confusion matrix
cm <- as.data.frame(h2o.confusionMatrix(perf.validation, cutoff.selected.model))
## enlist categories
lvs <- c("CP", "PDAC")
## truth
truth <- factor(rep(lvs, times = c(cm$CP[1] + cm$PDAC[1], cm$CP[2] + cm$PDAC[2])), levels = rev(lvs))
## pred
pred <- factor(c(rep(lvs, times = c(cm$CP[1], cm$PDAC[1])), rep(lvs, times = c(cm$CP[2], 
    cm$PDAC[2]))), levels = rev(lvs))
## xtab
xtab <- table(pred, truth)
## confusion matrix
cm <- confusionMatrix(xtab, positive = "PDAC", prevalence = prevalence)
cm
plotCM(cm)
```

## model statistics
```{r}
cv.results <- data.frame()
# split data for 10 fold cross validation ------------ Create 10 equally size folds
folds <- cut(seq(1, nrow(validation)), breaks = 10, labels = FALSE)
# performance on 10 fold cross validation ----------------
for (i in 1:10) {
  # Segement your data by fold using the which() function
  Indexes <- which(folds == i, arr.ind = TRUE)
  test.cv <- validation[-Indexes, ]
  perf.cv <- h2o.performance(base$model, newdata = test.cv)
  
  cm <- as.data.frame(h2o.confusionMatrix(perf.cv, cutoff.selected.model))
  ## enlist categories
  lvs <- c("CP", "PDAC")
  ## truth
  truth <- factor(rep(lvs, times = c(cm$CP[1] + cm$PDAC[1], cm$CP[2] + cm$PDAC[2])), levels = rev(lvs))
  ## pred
  pred <- factor(c(rep(lvs, times = c(cm$CP[1], cm$PDAC[1])), rep(lvs, times = c(cm$CP[2],
                                                                                 cm$PDAC[2]))), levels = rev(lvs))
  ## xtab
  xtab <- table(pred, truth)
  ## confusion matrix
  cm <- confusionMatrix(xtab, positive = "PDAC", prevalence = prevalence)
  
  cv.results[i, 1] <- i
  cv.results[i, 2] <- perf.cv@metrics$MSE
  cv.results[i, 3] <- perf.cv@metrics$RMSE
  cv.results[i, 4] <- perf.cv@metrics$r2
  cv.results[i, 5] <- perf.cv@metrics$logloss
  cv.results[i, 6] <- perf.cv@metrics$AUC
  cv.results[i, 7] <- perf.cv@metrics$pr_auc
  cv.results[i, 8] <- perf.cv@metrics$Gini
  cv.results[i, 9] <- perf.cv@metrics$mean_per_class_error
  cv.results[i, 10] = cm$overall["Accuracy"]
  cv.results[i, 11] = cm$byClass["Specificity"]
  cv.results[i, 12] = cm$byClass["Sensitivity"]
  cv.results[i, 13] = cm$byClass["Pos Pred Value"]
  cv.results[i, 14] = cm$byClass["Neg Pred Value"]
}

colnames(cv.results) <- c("fold", "MSE", "RMSE", "R2", "logloss", "AUC", "PRAUC", "Gini", 
                          "Mean_per_class_error", "accuracy", "specificity", "sensitivity", "ppv", "npv")

cv.results.summary <- 
  cv.results[, !colnames(cv.results) %in% "fold"] %>% gather(factor_key = TRUE) %>% 
  group_by(key) %>% summarise(mean = mean(value), sd = sd(value), max = max(value), 
                              min = min(value), 
                              n  = n(),
                              se = sd / sqrt(n),
                              lower.ci = mean - qt(1 - (0.05 / 2), n - 1) * se,
                              upper.ci = mean + qt(1 - (0.05 / 2), n - 1) * se)
cv.results.summary
```

## roc: test

```{r}
p <-
  list(base$performance, h2o.performance(base$model, newdata = validation)) %>%
  map(
    function(x)
      x %>%
      .@metrics %>%
      .$thresholds_and_metric_scores %>%
      .[c('tpr', 'fpr')] %>%
      add_row(tpr = 0, fpr = 0, .before = T) %>%
      add_row(tpr = 0, fpr = 0, .before = F)
  ) %>%
  map2(c("test", "validation"),
       function(x, y)
         x %>%
         add_column(model = y)) %>%
  reduce(rbind) %>%
  # plot fpr and tpr, map model to color as grouping
  ggplot(aes(fpr, tpr, col = model)) +
  geom_line(size = 1.5) +
  geom_segment(aes(
    x = 0,
    y = 0,
    xend = 1,
    yend = 1
  ),
  linetype = 2,
  col = '#80796BFF') +
  xlab('False Positive Rate') +
  ylab('True Positive Rate') +
  ggtitle('Comparision of ROC curves of different learners: test') +
  theme_bw() +
  scale_color_manual(values = brewer.pal(3, "Set1")) +
  theme(
    axis.line = element_line(size = 0.75),
    axis.text = element_text(
      size = 11,
      face = "bold",
      colour = "black"
    ),
    axis.title = element_text(size = 12, face = "bold"),
    legend.title =  element_text(
      size = 12,
      face = "bold",
      colour = "black"
    ),
    legend.text = element_text(
      size = 11,
      face = "bold",
      colour = "black"
    )
  ) +
  theme(legend.position = c(0.75, 0.25))

print(p)

save_plot(
  "./svg/ROC_test_lowCA.svg",
  fig = p,
  width = 8,
  height = 8,
  dpi = 300
)
```

# computing environment
```{r}
h2o.shutdown(prompt = FALSE)
sessionInfo()
```

