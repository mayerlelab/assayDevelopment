---
title: "assay developement"
subtitle: "__machine learning base learner__"
author: "_umahajan_"
date:  "`r format(Sys.time(), '%d %B, %Y')`"
output:
 html_notebook:
    theme: united
    number_sections: yes
    toc: yes
    toc_depth: 4
    toc_float: true
---

```{r setup, include=FALSE}
chooseCRANmirror(graphics = TRUE, ind = 1)
knitr::opts_chunk$set(
  tidy.opts = list(width.cutoff = 85),
  tidy = TRUE,
  echo = TRUE,
  warning = FALSE,
  message = FALSE
)
```

# load packages and datasets
```{r packages}
rm(list = ls())
##---------------------------------------------------------------
##                      required packages                      --
##---------------------------------------------------------------
scriptLibraries <-  c(
  "here",
  "dplyr",
  "openxlsx",
  "janitor",
  "rmarkdown",
  "knitr",
  "kableExtra",
  "tidyr",
  "ggplot2",
  "ggridges",
  "arsenal",
  "RColorBrewer",
  "h2o",
  "caret",
  "lime",
  "ggpubr",
  "sjPlot",
  "fmsb",
  "auctestr",
  "purrr",
  "tibble"
)
##---------------------------------------------------------------
##                      load functions                         --
##---------------------------------------------------------------
source("~/r_functions/basicFunctions.R")
source("~/r_functions/runH2Omodels.R") ## require to load h2o 
##---------------------------------------------------------------
##                        load packages                        --
##---------------------------------------------------------------
installScriptLibs(scriptLibraries)
##----------------------------------------------------------------
##                         basic themes                         --
##----------------------------------------------------------------
ggplot_theme <- theme_bw() +
  theme(
    axis.line = element_line(size = 0.75),
    axis.text = element_text(
      size = 11,
      face = "bold",
      colour = "black"
    ),
    axis.title = element_text(size = 12, face = "bold")
  )
##---------------------------------------------------------------
##                    set working directory                    --
##---------------------------------------------------------------
here::here()
```

## initiate h2o
```{r h2o}
##----------------------------------------------------------------
##             detect the number of cores available             --
##----------------------------------------------------------------
myCores = parallel::detectCores(all.tests = TRUE) - 1

if (myCores > 20) {
  myCores = 20
} else
  myCores = myCores


memFreeG = 50
# Sys.setenv(JAVA_HOME = "/dss/dsshome1/lxc00/ru64waf2/bin/jdk-13.0.2")
##----------------------------------------------------------------
##                         initiate h2o                         --
##----------------------------------------------------------------
h2o.init(
  nthreads = myCores,
  min_mem_size = paste(memFreeG, "g", sep = ""),
  max_mem_size = paste(memFreeG, "g", sep = "")
)
h2o.no_progress()
h2o.removeAll()
```

# keys

```{r keys}
##---------------------------------------------------------------
##                         define keys                         --
##---------------------------------------------------------------
time <- 12*60*60
```

# load data
```{r dat}
##---------------------------------------------------------------
##                          load data                          --
##---------------------------------------------------------------
train <- readRDS("./ml_dataset/ImputedTrain.rds")
testComplete <- readRDS("./ml_dataset/ImputedTest.rds")
test <- testComplete[!testComplete$Diagnosis %in% "Non-pancreatic control",]
validationComplete <- readRDS("./ml_dataset/ImputedValidation.rds")
validation <- validationComplete[!validationComplete$Diagnosis %in% "Non-pancreatic control",]
# load metabolite names ---------------------------------------------------
metaboliteNames <- 
 read.csv("./masterTable/masterTableMetaboliteNames.csv",
          stringsAsFactors = FALSE)
```

## define response and features
```{r response}
##----------------------------------------------------------------
##                   define response variable                   --
##----------------------------------------------------------------
response <- "Disease_status"
train[[response]] <- as.factor(train[[response]])
test[[response]] <- as.factor(test[[response]])
validation[[response]] <- as.factor(validation[[response]])
##----------------------------------------------------------------
##                        merge features                        --
##----------------------------------------------------------------
columnToselect <- c( "^X", response, "CA19_9")
features <-
 setdiff(colnames(train)[grepl(paste(columnToselect, collapse ="|"), colnames(train))], response)
```

# Exploratory data analysis
```{r eda}
##---------------------------------------------------------------
##             create results/prediction directory             --
##---------------------------------------------------------------
ifelse(!dir.exists(file.path(paste0(here()), "h2o_results")),
       dir.create(file.path(paste0(here()), "h2o_results")), 
       FALSE)
## save pdfs
pdf("./h2o_results/eda.pdf", 
    paper= "a4",
    onefile = TRUE)
## plot distribution Train
a <- train %>%
  ggplot(aes(x = Disease_status, fill = Disease_status)) +
  geom_bar() +
  guides(fill = FALSE) +
  geom_label(stat = 'count', aes(label = ..count..), size = 7) +
  ggplot_theme +
  ggtitle("training set") +
  xlab("") +
  scale_fill_manual(values = c("#E41A1C", "#377EB8"))
## plot distribution Test
b <- test %>%
  ggplot(aes(x = Disease_status, fill = Disease_status)) +
  geom_bar() +
  guides(fill = FALSE) +
  geom_label(stat = 'count', aes(label = ..count..), size = 7) +
  ggplot_theme +
  ggtitle("testing set") +
  xlab("") +
  scale_fill_manual(values = c("#E41A1C", "#377EB8"))
## plot distribution validatio
c <- validation %>%
  ggplot(aes(x = Disease_status, fill = Disease_status)) +
  geom_bar() +
  guides(fill = FALSE) +
  geom_label(stat = 'count', aes(label = ..count..), size = 7) +
  ggplot_theme +
  ggtitle("validation set") +
  xlab("") +
  scale_fill_manual(values = c("#E41A1C", "#377EB8"))
## merge
p <- ggarrange(a, b, c, ncol = 3, labels = c("A", "B", "C"))
              
print(p)
dev.off()

print(p)
```

# automl modelling

## h2o dataframe
```{r h2o df}
##----------------------------------------------------------------
##                        convert h2o df                        --
##----------------------------------------------------------------
train <- as.h2o(train)
test <- as.h2o(test)
validation <- as.h2o(validation)
```

## h2o results
```{r res}
ifelse(!dir.exists(file.path(paste0(here()), "h2o_results/base")),
       dir.create(file.path(paste0(here()), "h2o_results/base")), 
       FALSE)
ifelse(!dir.exists(file.path(paste0(here()), "h2o_results/iteration")),
       dir.create(file.path(paste0(here()), "h2o_results/iteration")), 
       FALSE)
ifelse(!dir.exists(file.path(paste0(here()), "h2o_results/feature_reduction")),
       dir.create(file.path(paste0(here()), "h2o_results/feature_reduction")), 
       FALSE)
ifelse(!dir.exists(file.path(paste0(here()), "h2o_results/leave_one_out")),
       dir.create(file.path(paste0(here()), "h2o_results/leave_one_out")), 
       FALSE)
```

## select h2o model

```{r h2o fun}
## base model
banner("base model")
base <- runBaseModel(train = train,
                     test = test,
                     features = features,
                     response = response,
                     time = time,
                     exclude_algos = c("XGBoost", "DeepLearning", "StackedEnsemble"),
                     save.location = "./h2o_results/base/", cutoff_metric = "f1")
## plot
p <- base$plot
print(p)
save_plot(
  "./svg/h2o_varImp_base.svg",
  fig = p,
  width = 15,
  height = 9,
  dpi = 300
)
## lederboard
head(base$leaderboard)
## model performance
base$performance
## summary
tab_df(base$result)
## cross validation score
tab_df(base$cv.results)

## iteration model
banner("iterative model")
iteration <- runIterativeModel(model = base$model,
                               train,
                     test = test,
                     features = features,
                     response = response,
                     time = time,
                     save.location = "./h2o_results/iteration/",
                     cutoff_metric = "f1")

## plot
p <- iteration$plot
print(p)
save_plot(
  "./svg/h2o_varImp_itr.svg",
  fig = p,
  width = 15,
  height = 9,
  dpi = 300
)
## summary
iteration$result
## model performance
iteration$performance
## summary
iteration$confusionMatrix
## cross validation score
tab_df(iteration$cv.results)

## feature reduction
banner("feature reduction model")
feature.reduction <- runFeatureReduction(model = iteration$model,
                               train = train,
                               test = test,
                               response = response,
                               time = time,
                               save.location = "./h2o_results/feature_reduction/", 
                               cutoff_metric = "f1")

## plot
p <- feature.reduction$plot + geom_vline(xintercept = 6.5)
print(p)
save_plot(
  "./svg/h2o_feature_reduction.svg",
  fig = p,
  width = 15,
  height = 9,
  dpi = 300
)
## summary
tab_df(feature.reduction$data)

### model
banner("model selection")
model.feature.reduction <- feature.reduction$data$model[feature.reduction$data$number.of.features==6]
selected.model <- h2o.loadModel(paste0("./h2o_results/feature_reduction/", model.feature.reduction))
## performance of selected model
selected.model.perf <- h2o.performance(selected.model)

## leave one out
banner("influence of leave one out feature")
leave.one.out <- runLeaveOneOut(model = selected.model,
                               train = train,
                               test = test,
                               response = response,
                               time = time,
                               save.location = "./h2o_results/leave_one_out/",
                               cutoff_metric = "f1")
## plot
p <- leave.one.out$plot
print(p)
save_plot(
  "./svg/h2o_leave_one_out.svg",
  fig = p,
  width = 15,
  height = 9,
  dpi = 300
)
## summary
leave.one.out$data
```

## selected model summary

```{r}
p <- plotVarImp(selected.model)

## print
print(p)
save_plot(
  "./svg/h2o_varImp_selectedModel.svg",
  fig = p,
  width = 15,
  height = 9,
  dpi = 300
)

prevalence = 1.95/100

banner("test performance")
perf.test <- h2o.performance(selected.model, test)
perf.test
## cutoff of selected model
cutoff.selected.model <- h2o.find_threshold_by_max_metric(perf.test, "f1")
## confusion matrix
cm <- as.data.frame(h2o.confusionMatrix(perf.test, cutoff.selected.model))
## enlist categories
lvs <- c("CP", "PDAC")
## truth
truth <- factor(rep(lvs, times = c(cm$CP[1] + cm$PDAC[1], cm$CP[2] + cm$PDAC[2])), levels = rev(lvs))
## pred 
pred <- factor(c(rep(lvs, times = c(cm$CP[1], cm$PDAC[1])), rep(lvs, times = c(cm$CP[2], 
    cm$PDAC[2]))), levels = rev(lvs))
## xtab
xtab <- table(pred, truth)
## confusion matrix
cm <- confusionMatrix(xtab, positive = "PDAC", prevalence = prevalence)
cm
plotCM(cm)


banner("validation performance")
perf.validation <- h2o.performance(selected.model, validation)
perf.validation
## confusion matrix
cm <- as.data.frame(h2o.confusionMatrix(perf.validation, cutoff.selected.model))
## enlist categories
lvs <- c("CP", "PDAC")
## truth
truth <- factor(rep(lvs, times = c(cm$CP[1] + cm$PDAC[1], cm$CP[2] + cm$PDAC[2])), levels = rev(lvs))
## pred
pred <- factor(c(rep(lvs, times = c(cm$CP[1], cm$PDAC[1])), rep(lvs, times = c(cm$CP[2], 
    cm$PDAC[2]))), levels = rev(lvs))
## xtab
xtab <- table(pred, truth)
## confusion matrix
cm <- confusionMatrix(xtab, positive = "PDAC", prevalence = prevalence)
cm
plotCM(cm)
```

## roc: test

```{r}
p <-
  list(base$performance, iteration$performance, h2o.performance(selected.model, newdata = test)) %>%
  map(
    function(x)
      x %>%
      .@metrics %>%
      .$thresholds_and_metric_scores %>%
      .[c('tpr', 'fpr')] %>%
      add_row(tpr = 0, fpr = 0, .before = T) %>%
      add_row(tpr = 0, fpr = 0, .before = F)
  ) %>%
  map2(c("Base model", "Iterated model", "Selected model"),
       function(x, y)
         x %>%
         add_column(model = y)) %>%
  reduce(rbind) %>%
  # plot fpr and tpr, map model to color as grouping
  ggplot(aes(fpr, tpr, col = model)) +
  geom_line(size = 1.5) +
  geom_segment(aes(
    x = 0,
    y = 0,
    xend = 1,
    yend = 1
  ),
  linetype = 2,
  col = '#80796BFF') +
  xlab('False Positive Rate') +
  ylab('True Positive Rate') +
  ggtitle('Comparision of ROC curves of different learners: test') +
  theme_bw() +
  scale_color_manual(values = brewer.pal(3, "Set1")) +
  theme(
    axis.line = element_line(size = 0.75),
    axis.text = element_text(
      size = 11,
      face = "bold",
      colour = "black"
    ),
    axis.title = element_text(size = 12, face = "bold"),
    legend.title =  element_text(
      size = 12,
      face = "bold",
      colour = "black"
    ),
    legend.text = element_text(
      size = 11,
      face = "bold",
      colour = "black"
    )
  ) +
  theme(legend.position = c(0.75, 0.25))

print(p)

save_plot(
  "./svg/ROC_test.svg",
  fig = p,
  width = 8,
  height = 8,
  dpi = 300
)
```

## roc: validation

```{r}
p <-
  list(h2o.performance(base$model, newdata = validation), 
h2o.performance(iteration$model, newdata = validation), 
h2o.performance(selected.model, newdata = validation)) %>%
  map(
    function(x)
      x %>%
      .@metrics %>%
      .$thresholds_and_metric_scores %>%
      .[c('tpr', 'fpr')] %>%
      add_row(tpr = 0, fpr = 0, .before = T) %>%
      add_row(tpr = 0, fpr = 0, .before = F)
  ) %>%
  map2(c("Base model", "Iterated model", "Selected model"),
       function(x, y)
         x %>%
         add_column(model = y)) %>%
  reduce(rbind) %>%
  # plot fpr and tpr, map model to color as grouping
  ggplot(aes(fpr, tpr, col = model)) +
  geom_line(size = 1.5) +
  geom_segment(aes(
    x = 0,
    y = 0,
    xend = 1,
    yend = 1
  ),
  linetype = 2,
  col = '#80796BFF') +
  xlab('False Positive Rate') +
  ylab('True Positive Rate') +
  ggtitle('Comparision of ROC curves of different learners: validation') +
  theme_bw() +
  scale_color_manual(values = brewer.pal(3, "Set1")) +
  theme(
    axis.line = element_line(size = 0.75),
    axis.text = element_text(
      size = 11,
      face = "bold",
      colour = "black"
    ),
    axis.title = element_text(size = 12, face = "bold"),
    legend.title =  element_text(
      size = 12,
      face = "bold",
      colour = "black"
    ),
    legend.text = element_text(
      size = 11,
      face = "bold",
      colour = "black"
    )
  ) +
  theme(legend.position = c(0.75, 0.25))

print(p)

save_plot(
  "./svg/ROC_validation.svg",
  fig = p,
  width = 8,
  height = 8,
  dpi = 300
)
```

## black box visualization
```{r}
variables <- selected.model@parameters$x
variablesNames <- c()
# metabolite ID to metabolite names 
variablesX <- gsub("^X", "", variables)
matchColumnNames <-
  match(variablesX, metaboliteNames$ID, nomatch = 0)
variablesNames[variablesX %in% metaboliteNames$ID] <-
  metaboliteNames$METABOLITE_NAME[matchColumnNames]
variablesNames[is.na(variablesNames)] <- "CA19.9"

for (i in seq_along(variables)) {
  banner(variablesNames[i])
  p <- h2o.pd_plot(selected.model, test, variables[i])
  print(p)
}

print(variablesNames)

```

# computing environment
```{r}
h2o.shutdown(prompt = FALSE)
sessionInfo()
```

